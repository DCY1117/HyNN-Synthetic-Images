# HyNN-Synthetic-Images
In the field of machine learning, the absence of spatial structure in tabular data poses significant limitations on the applicability of Convolutional Neural Networks (CNNs). To address this issue, various works have emerged by converting such data into images, encapsulating feature similarities within a spatial context and thus broadening the application of CNNs to this type of data. This study delves into various techniques for converting tabular data into synthetic images to develop hybrid models that combine different architectures. Specifically, we propose two novel hybrid architectures: Hybrid Neural Network (HyNN), which combines a Convolutional Neural Network for analysing synthetic images and a Multilayer Perceptron for tabular data; and Hybrid Vision Transformer (HyViT), which employs a Vision Transformer for analysing synthetic images and a Multilayer Perceptron for tabular data. Through rigorous experimentation, focused on a regression problem using a MIMO indoor localization dataset, we benchmarked HyViT against classical regression algorithms and various HyNN configurations. Notably, the HyViT model achieves the lowest RMSE outperforming the HyNN counterparts, and the best classical regression model KNN. These findings underscore the potential of synthetic images and hybrid architectural innovations in enhancing deep learning models, offering a promising avenue for future research and application in diverse fields.
